{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiobgakmXiOq"
      },
      "source": [
        "_________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evlp7tblTonm"
      },
      "source": [
        "##CV ASSIGNMENT 2\n",
        "\n",
        "###NAME : GABRIEL JOSHUA R\n",
        "\n",
        "###REG NO. : 20MIA1100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJZ4G24JXhEk"
      },
      "source": [
        "_________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c-oo87lTXwJ"
      },
      "source": [
        "#OPTICAL FLOW :\n",
        "\n",
        "It allows us to understand how objects in a scene are moving and changing over time. This information can be used for a variety of tasks, such as tracking moving objects, stabilizing video footage, or generating realistic visual effects. To estimate optical flow, computer vision algorithms typically rely on assumptions about the properties of the scene, such as brightness constancy and smoothness. These algorithms use techniques such as the Lucas-Kanade method or Horn-Schunck algorithm to compute the optical flow field from a sequence of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7z1LaIyXYd0"
      },
      "source": [
        "_________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Foir8jP89xYV"
      },
      "source": [
        "###Optical Flow with Lucas-Kanade method\n",
        "\n",
        "The Lucas-Kanade method is a local optical flow algorithm that assumes the motion of a pixel is constant over a small region around it. It computes the displacement vector for each pixel by solving a set of linear equations based on the gradient and spatiotemporal derivatives of the image. The algorithm works well for small displacements and small changes in illumination but can fail for large displacements or occlusions. It does not handle changes in scene geometry or camera motion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl5UJ5ZtUh_-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcykiHsORyCT"
      },
      "outputs": [],
      "source": [
        "vdo = cv.VideoCapture(\"/content/car1.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p-clrfEqo-Q"
      },
      "outputs": [],
      "source": [
        "# params for ShiTomasi corner detection\n",
        "feature_params = dict( maxCorners = 100,\n",
        "                       qualityLevel = 0.3,\n",
        "                       minDistance = 7,\n",
        "                       blockSize = 7 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAgqkLVEqta4"
      },
      "outputs": [],
      "source": [
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict( winSize  = (15, 15),\n",
        "                  maxLevel = 2,\n",
        "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp4I26rmqv7X"
      },
      "outputs": [],
      "source": [
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (100, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j515bfgqyzf"
      },
      "outputs": [],
      "source": [
        "# Take first frame and find corners in it\n",
        "ret, old_frame = vdo.read()\n",
        "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
        "p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vX0e5iWbq13w"
      },
      "outputs": [],
      "source": [
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "while(1):\n",
        "    ret, frame = vdo.read()\n",
        "    if not ret:\n",
        "        print('end of frame')\n",
        "        break\n",
        "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    # calculate optical flow\n",
        "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "    # Select good points\n",
        "    if p1 is not None:\n",
        "        good_new = p1[st==1]\n",
        "        good_old = p0[st==1]\n",
        "    # draw the tracks\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "    img = cv.add(frame, mask)\n",
        "    cv2_imshow(img)\n",
        "    k = cv.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "    # Now update the previous frame and previous points\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TJ9X4bZXzE9"
      },
      "source": [
        "_________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0-pLGi5-UGY"
      },
      "source": [
        "##Gunnar-Farneback optical flow\n",
        "\n",
        "Gunnar-Farneback optical flow is a dense optical flow algorithm that estimates the motion of all pixels between two frames. It computes the optical flow field by analyzing the polynomial expansion of the image brightness function. The algorithm uses a pyramidal approach to estimate the motion of pixels at different scales. It is computationally intensive but can handle large displacements and changes in illumination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1rlT_i2ETvPC"
      },
      "outputs": [],
      "source": [
        "vdo = cv.VideoCapture(cv.samples.findFile(\"/content/car1.mp4\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d7psu-tjtYCG"
      },
      "outputs": [],
      "source": [
        "ret, frame1 = vdo.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VXUJt1KxtaSV"
      },
      "outputs": [],
      "source": [
        "prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8soyHaCFtgOn"
      },
      "outputs": [],
      "source": [
        "hsv = np.zeros_like(frame1)\n",
        "hsv[..., 1] = 255\n",
        "while(1):\n",
        "    ret, frame2 = vdo.read()\n",
        "    if not ret:\n",
        "        print('end of frame')\n",
        "        break\n",
        "    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
        "    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang*180/np.pi/2\n",
        "    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
        "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
        "    cv2_imshow(bgr)\n",
        "    prvs = next\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE0Fl6KLaX09"
      },
      "source": [
        "###INFERENCE :\n",
        "\n",
        "Both the above methods is efficiently able to detect the relative motion of the car and the surroundings. Based on the memory requirement, Lucas-Kanade is better as it uses only the important features from the frames of video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mY_HiAnY0Ib"
      },
      "source": [
        "_________________________________________________________________________________________"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}